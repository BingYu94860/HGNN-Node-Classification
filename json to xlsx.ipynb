{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T05:28:29.839216Z",
     "start_time": "2021-08-01T05:28:29.184748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GCN_citeseer', 'GCN_cora', 'GCN_pubmed', 'GCN_v2_citeseer', 'GCN_v2_cora', 'GCN_v2_pubmed']\n",
      "C:\\Users\\BingYu\\Documents\\GitHub\\HGNN-Node-Classification\\json_random\\GCN_cora\n",
      "C:\\Users\\BingYu\\Documents\\GitHub\\HGNN-Node-Classification\\json_random\\GCN_v2_cora\n",
      "C:\\Users\\BingYu\\Documents\\GitHub\\HGNN-Node-Classification\\json_random\\GCN_citeseer\n",
      "C:\\Users\\BingYu\\Documents\\GitHub\\HGNN-Node-Classification\\json_random\\GCN_v2_citeseer\n",
      "C:\\Users\\BingYu\\Documents\\GitHub\\HGNN-Node-Classification\\json_random\\GCN_pubmed\n",
      "C:\\Users\\BingYu\\Documents\\GitHub\\HGNN-Node-Classification\\json_random\\GCN_v2_pubmed\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "import numpy as np\n",
    "\n",
    "# 選擇資料夾\n",
    "folder_name = 'json_public' # json_public json_random\n",
    "\n",
    "# root/folder/subfolder/flie.json\n",
    "root = os.getcwd()\n",
    "folder_path = os.path.join(root, folder_name)\n",
    "\n",
    "print(os.listdir(folder_path))\n",
    "\n",
    "subfolder_names = [\n",
    "    'GCN_cora',\n",
    "    'GCN_v2_cora',\n",
    "    \n",
    "    'GCN_citeseer',\n",
    "    'GCN_v2_citeseer',\n",
    "    \n",
    "    'GCN_pubmed',\n",
    "    'GCN_v2_pubmed',\n",
    "]\n",
    "\n",
    "# 讀取所有 json 檔案\n",
    "dict_dict_json = {}  # {key: file_name, value: json_file_date}\n",
    "\n",
    "for subfolder_name in subfolder_names:\n",
    "    subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "    #subfolder_path = folder_path\n",
    "    print(subfolder_path)\n",
    "    for file_name in os.listdir(subfolder_path):\n",
    "        #print(f\"\\t{file_name}\")\n",
    "        file_path = os.path.join(subfolder_path, file_name)\n",
    "        with open(file_path, 'r') as f:\n",
    "            dict_dict_json[file_name] = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T05:28:30.323315Z",
     "start_time": "2021-08-01T05:28:29.840216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: C:\\Users\\BingYu\\Documents\\GitHub\\HGNN-Node-Classification\\info_json_random.xlsx\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "xlsx_name = f\"info_{folder_name}.xlsx\"\n",
    "xlsx_path = os.path.join(root, xlsx_name)\n",
    "\n",
    "if os.path.isfile(xlsx_path):\n",
    "    wb = openpyxl.load_workbook(xlsx_path)\n",
    "    print(f\"path: {xlsx_path} 已存在.\")\n",
    "else:\n",
    "    wb = openpyxl.Workbook()\n",
    "    print(f\"path: {xlsx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T05:28:30.339246Z",
     "start_time": "2021-08-01T05:28:30.325283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_keys = ['weight_decay', 'model', 'GPU']\n",
      "not_keys = ['project_name', 'num_class', 'validation_split', 'loss', 'batch_size', 'model_name', 'layer1_list', 'layer2_list', 'fc_list', 'dropout_rate', 'image_adjs', 'image_adj', 'polar_adjs', 'polar_adj', 'kernel_size', 'num_K', 'num_theta', 'num_radius', 'gpu_name', 'is_features', 'isBatchNorm', 'use_residual', 'use_inception']\n"
     ]
    }
   ],
   "source": [
    "# [json_file_date, ...]\n",
    "list_dict_json = list(dict_dict_json.values())\n",
    "\n",
    "dict_json_keys = list(list_dict_json[0].keys())\n",
    "\n",
    "file_keys = ['project_name', 'save_time']\n",
    "\n",
    "same_keys = ['dataset', 'num_class', 'validation_split', 'loss', 'optimizers', 'learning_rate', 'epochs', 'batch_size',\n",
    "            'model_name', 'layer1_list', 'layer2_list', 'fc_list', 'dropout_rate']\n",
    "\n",
    "#    GCN : 'image_adjs'\n",
    "# Cb GCN : 'image_adj', 'num_K'\n",
    "#   PGCN : 'polar_adjs', 'input_shape', 'num_theta', 'num_radius'\n",
    "# CbPGCN : 'polar_adj', 'num_K', 'input_shape', 'num_theta', 'num_radius'\n",
    "#    CNN : 'kernel_size'\n",
    "main_keys = ['image_adjs', 'image_adj', 'polar_adjs', 'polar_adj', 'kernel_size']\n",
    "submain_keys = ['num_K', 'num_theta', 'num_radius']\n",
    "\n",
    "date_keys = ['train_acc', 'train_loss', 'val_acc', 'val_loss', 'test_acc', 'test_loss', 'train_time', 'total_params']\n",
    "subdata_keys = ['gpu_name', 'test_time']\n",
    "history_keys = ['history_epoch', 'history_loss', 'history_accuracy', 'history_val_loss', 'history_val_accuracy']\n",
    "\n",
    "# 未使用\n",
    "None_keys = ['is_features', 'isBatchNorm', 'use_residual', 'use_inception']\n",
    "\n",
    "all_keys = file_keys+same_keys+main_keys+submain_keys+date_keys+subdata_keys+history_keys+None_keys\n",
    "\n",
    "other_keys = []\n",
    "for key in dict_json_keys:\n",
    "    if key not in all_keys:\n",
    "        other_keys.append(key)\n",
    "print(f'other_keys = {other_keys}')\n",
    "\n",
    "not_keys = []\n",
    "for key in all_keys:\n",
    "    if key not in dict_json_keys:\n",
    "        not_keys.append(key)\n",
    "print(f'not_keys = {not_keys}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T05:28:31.104532Z",
     "start_time": "2021-08-01T05:28:30.340242Z"
    }
   },
   "outputs": [],
   "source": [
    "info_keys = file_keys+same_keys+main_keys+submain_keys+date_keys+subdata_keys+None_keys+other_keys+history_keys\n",
    "\n",
    "if 'Main' in wb.sheetnames:\n",
    "    ws = wb['Main']\n",
    "else:\n",
    "    ws = wb.create_sheet('Main')\n",
    "    ws.append(info_keys)\n",
    "\n",
    "\n",
    "for file_name, dict_value in dict_dict_json.items():\n",
    "    row_data = []\n",
    "    for key in info_keys:\n",
    "        \n",
    "        if key not in dict_value.keys():\n",
    "            data = '-'\n",
    "        else:\n",
    "            data = dict_value[key]\n",
    "        \n",
    "        if type(data) == list:\n",
    "            data = str(data)\n",
    "        elif data == None:\n",
    "            data = 'None'\n",
    "        \n",
    "        row_data.append(data)\n",
    "    ws.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T05:28:31.136462Z",
     "start_time": "2021-08-01T05:28:31.106521Z"
    }
   },
   "outputs": [],
   "source": [
    "data_keys = [\n",
    "    'train_acc', 'train_loss', 'val_acc', 'val_loss', 'test_acc', 'test_loss',\n",
    "    'train_time', 'total_params'\n",
    "]\n",
    "\n",
    "table_dict = {}\n",
    "for file_name, dict_value in dict_dict_json.items():\n",
    "\n",
    "    table_key = f\"{dict_value['model']}_{dict_value['dataset']}\"\n",
    "\n",
    "    # 增加一筆 table_key 欄位\n",
    "    if table_key not in table_dict.keys():\n",
    "        table_dict[table_key] = {}\n",
    "        for data_key in data_keys:\n",
    "            table_dict[table_key][data_key] = []\n",
    "    # 添加資料\n",
    "    for data_key in data_keys:\n",
    "        table_dict[table_key][data_key].append(dict_value[data_key])\n",
    "\n",
    "if 'Select' in wb.sheetnames:\n",
    "    ws = wb['Select']\n",
    "else:\n",
    "    ws = wb.create_sheet('Select')\n",
    "    ws.append(['table_key'] + data_keys)\n",
    "\n",
    "for table_key in subfolder_names:\n",
    "    if table_key in table_dict.keys():\n",
    "        item_dict = table_dict[table_key]\n",
    "    else:\n",
    "        print(f'table_key = {table_key} continue')\n",
    "        continue\n",
    "    ####<  >####\n",
    "    row_data = [table_key]\n",
    "    for data_key in data_keys:\n",
    "        data = np.array(item_dict[data_key])\n",
    "\n",
    "        #if data_key in ['train_acc', 'val_acc', 'test_acc']:\n",
    "        #    data = np.clip(data, 0, 1)\n",
    "        #    if data.max() > 1:\n",
    "        #        print(data)\n",
    "\n",
    "        data_mean = np.mean(data)\n",
    "        data_std = np.std(data)\n",
    "        if data_key in ['train_acc', 'val_acc', 'test_acc']:\n",
    "            data_str = f\"{data_mean*100:5.2f}±{data_std*100:4.2f}\"\n",
    "        elif data_key in ['train_loss', 'val_loss', 'test_loss']:\n",
    "            data_str = f\"{data_mean:5.3f}±{data_std:5.3f}\"\n",
    "        elif data_key == 'train_time':\n",
    "            data_str = f\"{data_mean:6.1f}±{data_std:3.1f}\"\n",
    "        elif data_key == 'total_params':\n",
    "            data_str = int(data_mean)\n",
    "        row_data.append(data_str)\n",
    "    ws.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T05:28:32.495888Z",
     "start_time": "2021-08-01T05:28:31.137460Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'Sheet' in wb.sheetnames: wb.remove(wb['Sheet'])\n",
    "wb.save(xlsx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
